# Example environment variables for local development (do not commit real secrets)

# --- AWS & Solution ---
AWS_REGION="eu-west-1"
SOLUTIONS_S3_BUCKET="<your_s3_bucket>"
SOLUTION_NAME="fraud-detection"
SECRETS_MANAGER_ID="<optional_secrets_manager_id>"  # optional, used in prod

# AWS credentials (only for local dev; prefer environment config or profiles)
AWS_ID_ACCESS_KEY="<your_access_key_id>"
AWS_SECRET_ACCESS_KEY="<your_secret_access_key>"

# --- Chalice API ---
# Lambda environment variables names are lowercase as used in app/chalice/app.py
# Use Terraform output 'kinesis_stream_name' for stream_name
stream_name="<kinesis_stream_name>"
solution_prefix="fraud-detection"
# Use your Terraform var 'aws_region' here (same as terraform var aws_region)
aws_region="eu-west-1"

# --- Local streaming job (Spark/Glue compatible) ---
# Use Terraform output 'kinesis_stream_name' for KINESIS_STREAM
KINESIS_STREAM="<kinesis_stream_name>"
# Use Terraform outputs 'rds_postgres_endpoint' and 'rds_postgres_port'
POSTGRES_HOST="<postgres_host>"
POSTGRES_PORT="5432"
POSTGRES_DB="fraudit_postgres_db"
POSTGRES_USER="postgres_user"
POSTGRES_PASSWORD="postgres_password"

# Optional paths
KINESIS_CONNECTOR_PATH="src/resources/spark-streaming-sql-kinesis-connector_2.12-1.0.0.jar"
CHECKPOINT_PATH="/tmp/fraudit-checkpoint"

# --- Use Chalice output API_URL after performing <chalice deploy> command ---
CHALICE_API_URL="https://xxxxx.execute-api.eu-west-1.amazonaws.com/api"