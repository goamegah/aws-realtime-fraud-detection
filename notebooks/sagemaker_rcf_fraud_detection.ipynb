{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Credit card fraud detection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this solution we will build the core of a credit card fraud detection system using SageMaker. We will start by training an anomaly detection algorithm, then proceed to train two XGBoost models for supervised training. To deal with the highly unbalanced data common in fraud detection, our first model will use re-weighting of the data, and the second will use re-sampling, using the popular SMOTE technique for oversampling the rare fraud data.\n",
    "\n",
    "Our solution includes an example of making calls to a REST API to simulate a real deployment, using AWS Lambda to trigger both the anomaly detection and XGBoost model.\n",
    "\n",
    "You can select Run->Run All from the menu to run all cells in Studio (or Cell->Run All in a SageMaker Notebook Instance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: When running this notebook on SageMaker Studio, you should make sure the 'SageMaker JumpStart Data Science 1.0' image/kernel is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T01:40:34.580160Z",
     "iopub.status.busy": "2025-06-17T01:40:34.579636Z",
     "iopub.status.idle": "2025-06-17T01:40:39.719363Z",
     "shell.execute_reply": "2025-06-17T01:40:39.718677Z",
     "shell.execute_reply.started": "2025-06-17T01:40:34.580132Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import xgboost as xgb\n",
    "import boto3\n",
    "import joblib\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T01:40:39.721044Z",
     "iopub.status.busy": "2025-06-17T01:40:39.720468Z",
     "iopub.status.idle": "2025-06-17T01:40:39.724420Z",
     "shell.execute_reply": "2025-06-17T01:40:39.723659Z",
     "shell.execute_reply.started": "2025-06-17T01:40:39.721014Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T01:40:39.725788Z",
     "iopub.status.busy": "2025-06-17T01:40:39.725362Z",
     "iopub.status.idle": "2025-06-17T01:40:39.731192Z",
     "shell.execute_reply": "2025-06-17T01:40:39.730378Z",
     "shell.execute_reply.started": "2025-06-17T01:40:39.725759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws_region: eu-west-1\n",
      "aws_access_key: AKIAYPN45FK4P7QDIR5R\n",
      "aws_secret_key: 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\n",
      "s3_bucket: credit-card-s3\n",
      "s3_prefix: fraud-detection\n"
     ]
    }
   ],
   "source": [
    "# Configuration des variables d'environnement\n",
    "aws_region = os.environ.get('AWS_REGION')\n",
    "aws_access_key = os.getenv(\"AWS_ID_ACCESS_KEY\")\n",
    "aws_secret_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "s3_bucket = os.getenv(\"SOLUTIONS_S3_BUCKET\")\n",
    "s3_prefix = os.getenv(\"SOLUTION_NAME\")\n",
    "\n",
    "print(f\"aws_region: {aws_region}\")\n",
    "print(f\"aws_access_key: {aws_access_key}\")\n",
    "print(f\"aws_secret_key: {aws_secret_key}\")\n",
    "print(f\"s3_bucket: {s3_bucket}\")\n",
    "print(f\"s3_prefix: {s3_prefix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T01:40:39.733098Z",
     "iopub.status.busy": "2025-06-17T01:40:39.732840Z",
     "iopub.status.idle": "2025-06-17T01:40:39.738035Z",
     "shell.execute_reply": "2025-06-17T01:40:39.737271Z",
     "shell.execute_reply.started": "2025-06-17T01:40:39.733076Z"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = 'dataset'\n",
    "os.makedirs(DATASET_PATH, exist_ok=True)\n",
    "# os.makedirs(CHECKPOINTS_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T01:40:39.739589Z",
     "iopub.status.busy": "2025-06-17T01:40:39.739301Z",
     "iopub.status.idle": "2025-06-17T01:40:40.019561Z",
     "shell.execute_reply": "2025-06-17T01:40:40.018740Z",
     "shell.execute_reply.started": "2025-06-17T01:40:39.739561Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialisation du client S3\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=aws_access_key,\n",
    "    aws_secret_access_key=aws_secret_key,\n",
    "    region_name=aws_region\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T01:40:40.021051Z",
     "iopub.status.busy": "2025-06-17T01:40:40.020593Z",
     "iopub.status.idle": "2025-06-17T01:40:40.666646Z",
     "shell.execute_reply": "2025-06-17T01:40:40.665799Z",
     "shell.execute_reply.started": "2025-06-17T01:40:40.021021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargement en cours...\n",
      "Téléchargement terminé : dataset/creditcard.csv.zip\n"
     ]
    }
   ],
   "source": [
    "# Download file from S3\n",
    "s3_key = f\"{s3_prefix}/dataset/creditcard.csv.zip\"\n",
    "local_zip_path = f\"{DATASET_PATH}/creditcard.csv.zip\"\n",
    "\n",
    "print(\"Téléchargement en cours...\")\n",
    "s3_client.download_file(s3_bucket, s3_key, local_zip_path)\n",
    "print(f\"Téléchargement terminé : {local_zip_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T01:40:40.668346Z",
     "iopub.status.busy": "2025-06-17T01:40:40.667330Z",
     "iopub.status.idle": "2025-06-17T01:40:42.219541Z",
     "shell.execute_reply": "2025-06-17T01:40:42.218721Z",
     "shell.execute_reply.started": "2025-06-17T01:40:40.668321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Décompression...\n",
      "Fichiers extraits dans le dossier 'dataset'.\n"
     ]
    }
   ],
   "source": [
    "# Unzip file to DATASET_PATH\n",
    "print(\"Décompression...\")\n",
    "with zipfile.ZipFile(local_zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(DATASET_PATH)\n",
    "print(f\"Fichiers extraits dans le dossier '{DATASET_PATH}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T01:40:42.220984Z",
     "iopub.status.busy": "2025-06-17T01:40:42.220664Z",
     "iopub.status.idle": "2025-06-17T01:40:42.235413Z",
     "shell.execute_reply": "2025-06-17T01:40:42.234676Z",
     "shell.execute_reply.started": "2025-06-17T01:40:42.220952Z"
    }
   },
   "outputs": [],
   "source": [
    "# (Optionnal) Remove zip file\n",
    "os.remove(local_zip_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate and process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by reading in the credit card fraud data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T01:40:42.236946Z",
     "iopub.status.busy": "2025-06-17T01:40:42.236602Z",
     "iopub.status.idle": "2025-06-17T01:40:44.742056Z",
     "shell.execute_reply": "2025-06-17T01:40:44.741229Z",
     "shell.execute_reply.started": "2025-06-17T01:40:42.236917Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(f\"{DATASET_PATH}/creditcard.csv\", delimiter=',')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a peek at our data (we only show a subset of the columns in the table):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T01:40:44.744242Z",
     "iopub.status.busy": "2025-06-17T01:40:44.743991Z",
     "iopub.status.idle": "2025-06-17T01:40:44.859122Z",
     "shell.execute_reply": "2025-06-17T01:40:44.858124Z",
     "shell.execute_reply.started": "2025-06-17T01:40:44.744221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
      "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
      "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
      "       'Class'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.168375e-15</td>\n",
       "      <td>3.416908e-16</td>\n",
       "      <td>-3.660091e-16</td>\n",
       "      <td>-1.227390e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2           V27           V28  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.168375e-15  3.416908e-16 -3.660091e-16 -1.227390e-16   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  4.036325e-01  3.300833e-01   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -2.256568e+01 -1.543008e+01   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -7.083953e-02 -5.295979e-02   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.342146e-03  1.124383e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  9.104512e-02  7.827995e-02   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  3.161220e+01  3.384781e+01   \n",
       "\n",
       "              Amount          Class  \n",
       "count  284807.000000  284807.000000  \n",
       "mean       88.349619       0.001727  \n",
       "std       250.120109       0.041527  \n",
       "min         0.000000       0.000000  \n",
       "25%         5.600000       0.000000  \n",
       "50%        22.000000       0.000000  \n",
       "75%        77.165000       0.000000  \n",
       "max     25691.160000       1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.columns)\n",
    "data[['Time', 'V1', 'V2', 'V27', 'V28', 'Amount', 'Class']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains\n",
    "only numerical features, because the original features have been transformed using PCA, to protect user privacy. As a result,\n",
    "the dataset contains 28 PCA components, V1-V28, and two features that haven't been transformed, _Amount_ and _Time_.\n",
    "_Amount_ refers to the transaction amount, and _Time_ is the seconds elapsed between any transaction in the data\n",
    "and the first transaction.\n",
    "\n",
    "The class column corresponds to whether or not a transaction is fraudulent. We see that the majority of data is non-fraudulent with only $492$ ($0.173\\%$) of the data corresponding to fraudulent examples, out of the total of 284,807 examples in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T01:40:44.860458Z",
     "iopub.status.busy": "2025-06-17T01:40:44.860144Z",
     "iopub.status.idle": "2025-06-17T01:40:44.873073Z",
     "shell.execute_reply": "2025-06-17T01:40:44.872414Z",
     "shell.execute_reply.started": "2025-06-17T01:40:44.860427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frauds:  492\n",
      "Number of non-frauds:  284315\n",
      "Percentage of fradulent data: 0.1727485630620034\n"
     ]
    }
   ],
   "source": [
    "nonfrauds, frauds = data.groupby('Class').size()\n",
    "print('Number of frauds: ', frauds)\n",
    "print('Number of non-frauds: ', nonfrauds)\n",
    "print('Percentage of fradulent data:', 100.*frauds/(frauds + nonfrauds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already know that the columns $V_i$ have been normalized to have $0$ mean and unit standard deviation as the result of a PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T01:40:44.874521Z",
     "iopub.status.busy": "2025-06-17T01:40:44.874110Z",
     "iopub.status.idle": "2025-06-17T01:40:44.911303Z",
     "shell.execute_reply": "2025-06-17T01:40:44.910523Z",
     "shell.execute_reply.started": "2025-06-17T01:40:44.874493Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_columns = data.columns[:-1]\n",
    "label_column = data.columns[-1]\n",
    "\n",
    "features = data[feature_columns].values.astype('float32')\n",
    "labels = (data[label_column].values).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will prepare our data for loading and training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split our dataset into a train and test to evaluate the performance of our models. It's important to do so _before_ any techniques meant to alleviate the class imbalance are used. This ensures that we don't leak information from the test set into the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T01:40:44.912592Z",
     "iopub.status.busy": "2025-06-17T01:40:44.912290Z",
     "iopub.status.idle": "2025-06-17T01:40:45.030019Z",
     "shell.execute_reply": "2025-06-17T01:40:45.029124Z",
     "shell.execute_reply.started": "2025-06-17T01:40:44.912563Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, labels, test_size=0.1, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: If you are bringing your own data to this solution and they include categorical data, that have strings as values, you'd need to one-hot encode these values first using for example sklearn's [OneHotEncoder](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-categorical-features), as XGBoost only supports numerical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T01:29:09.889705Z",
     "iopub.status.busy": "2025-06-17T01:29:09.887845Z",
     "iopub.status.idle": "2025-06-17T01:29:12.352737Z",
     "shell.execute_reply": "2025-06-17T01:29:12.352009Z",
     "shell.execute_reply.started": "2025-06-17T01:29:09.889652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "arn:aws:iam::582901115576:role/service-role/AmazonSageMaker-ExecutionRole-20250615T134459\n",
      "sagemaker-eu-west-1-582901115576\n",
      "Training artifacts will be uploaded to: s3://sagemaker-eu-west-1-582901115576/fraud-detection/output\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-eu-west-1-582901115576/fraud-detection/'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "\n",
    "\n",
    "# sagemaker_iam_role = os.getenv(\"SAGEMAKER_IAM_ROLE\")\n",
    "sagemaker_session = sagemaker.Session()\n",
    "sagemaker_iam_role = sagemaker.get_execution_role()\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "data_location = 's3://{}/{}/'.format(default_bucket, s3_prefix)\n",
    "base_job_name = \"{}-rcf\".format(s3_prefix)\n",
    "output_path = 's3://{}/{}/output'.format(default_bucket, s3_prefix)\n",
    "\n",
    "\n",
    "print(sagemaker_iam_role)\n",
    "print(default_bucket)\n",
    "print('Training artifacts will be uploaded to: {}'.format(output_path))\n",
    "data_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a fraud detection scenario, commonly we will have very few labeled examples, and it's possible that labeling fraud takes a very long time. We would like then to extract information from the unlabeled data we have at hand as well. _Anomaly detection_ is a form of unsupervised learning where we try to identify anomalous examples based solely on their feature characteristics. Random Cut Forest is a state-of-the-art anomaly detection algorithm that is both accurate and scalable. We will train such a model on our training data and evaluate its performance on our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T01:03:43.235437Z",
     "iopub.status.busy": "2025-06-17T01:03:43.235223Z",
     "iopub.status.idle": "2025-06-17T01:03:43.246220Z",
     "shell.execute_reply": "2025-06-17T01:03:43.245509Z",
     "shell.execute_reply.started": "2025-06-17T01:03:43.235418Z"
    }
   },
   "outputs": [],
   "source": [
    "from sagemaker import RandomCutForest\n",
    "\n",
    "# specify general training job information\n",
    "rcf = RandomCutForest(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=sagemaker_iam_role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    data_location=data_location,\n",
    "    output_path=output_path,\n",
    "    base_job_name=base_job_name,\n",
    "    num_samples_per_tree=512,\n",
    "    num_trees=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we are ready to fit the model. The below cell should take around 5 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-17T01:03:53.992Z",
     "iopub.execute_input": "2025-06-17T01:03:43.247200Z",
     "iopub.status.busy": "2025-06-17T01:03:43.246986Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Same images used for training and inference. Defaulting to image scope: inference.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: fraud-detection-rcf-2025-06-17-01-03-46-997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17 01:03:49 Starting - Starting the training job."
     ]
    }
   ],
   "source": [
    "rcf.fit(rcf.record_set(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Host Random Cut Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Once we have a trained model we can deploy it and get some predictions for our test set. SageMaker will spin up an instance for us and deploy the model, the whole process should take around 10 minutes, you will see progress being made with each `-` and an exclamation point when the process is finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-17T01:03:53.992Z"
    }
   },
   "outputs": [],
   "source": [
    "rcf_predictor = rcf.deploy(\n",
    "    model_name=\"{}-rcf\".format(s3_prefix),\n",
    "    endpoint_name=\"{}-rcf-endpoint\".format(s3_prefix),\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-17T01:03:53.992Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "rcf_predictor.content_type = 'text/csv'\n",
    "rcf_predictor.serializer = CSVSerializer()\n",
    "rcf_predictor.accept = 'application/json'\n",
    "rcf_predictor.deserializer = JSONDeserializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Random Cut Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "With the model deployed, let's see how it performs in terms of separating fraudulent from legitimate transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-17T01:03:53.992Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_rcf(current_predictor, data, rows=500):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = []\n",
    "    for array in split_array:\n",
    "        array_preds = [s['score'] for s in current_predictor.predict(array)['scores']]\n",
    "        predictions.append(array_preds)\n",
    "\n",
    "    return np.concatenate([np.array(batch) for batch in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-17T01:03:53.993Z"
    }
   },
   "outputs": [],
   "source": [
    "positives = X_test[y_test == 1]\n",
    "positives_scores = predict_rcf(rcf_predictor, positives)\n",
    "\n",
    "negatives = X_test[y_test == 0]\n",
    "negatives_scores = predict_rcf(rcf_predictor, negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-17T01:03:53.993Z"
    }
   },
   "outputs": [],
   "source": [
    "positives_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-17T01:03:53.993Z"
    }
   },
   "outputs": [],
   "source": [
    "negatives_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-17T01:03:53.993Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-17T01:03:53.993Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.histplot(positives_scores, label='fraud', bins=20, ax=ax)\n",
    "sns.histplot(negatives_scores, label='not-fraud', bins=20, ax=ax)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unsupervised model already can achieve some separation between the classes, with higher anomaly scores being correlated to fraud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "We will leave the unsupervised and base XGBoost endpoints running at the end of this notebook so we can handle incoming event streams using the Lambda function. The solution will automatically clean up the endpoints when deleted, however, don't forget to ensure the prediction endpoints are deleted when you're done. You can do that at the Amazon SageMaker console in the Endpoints page. Or you can run `predictor_name.delete_endpoint()` here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to clean up endpoints\n",
    "rcf_predictor.delete_model()\n",
    "rcf_predictor.delete_endpoint()\n",
    "sm_client = boto3.client('sagemaker', region_name=aws_region)\n",
    "waiter = sm_client.get_waiter('endpoint_deleted')\n",
    "waiter.wait(EndpointName=\"{}-rcf-endpoint\".format(s3_prefix))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data Acknowledgements\n",
    "\n",
    "The dataset used to demonstrated the fraud detection solution has been collected and analysed during a research collaboration of Worldline and the Machine Learning Group (http://mlg.ulb.ac.be) of ULB (Université Libre de Bruxelles) on big data mining and fraud detection. More details on current and past projects on related topics are available on https://www.researchgate.net/project/Fraud-detection-5 and the page of the [DefeatFraud](https://mlg.ulb.ac.be/wordpress/portfolio_page/defeatfraud-assessment-and-validation-of-deep-feature-engineering-and-learning-solutions-for-fraud-detection/) project\n",
    "We cite the following works:\n",
    "* Andrea Dal Pozzolo, Olivier Caelen, Reid A. Johnson and Gianluca Bontempi. Calibrating Probability with Undersampling for Unbalanced Classification. In Symposium on Computational Intelligence and Data Mining (CIDM), IEEE, 2015\n",
    "* Dal Pozzolo, Andrea; Caelen, Olivier; Le Borgne, Yann-Ael; Waterschoot, Serge; Bontempi, Gianluca. Learned lessons in credit card fraud detection from a practitioner perspective, Expert systems with applications,41,10,4915-4928,2014, Pergamon\n",
    "* Dal Pozzolo, Andrea; Boracchi, Giacomo; Caelen, Olivier; Alippi, Cesare; Bontempi, Gianluca. Credit card fraud detection: a realistic modeling and a novel learning strategy, IEEE transactions on neural networks and learning systems,29,8,3784-3797,2018,IEEE\n",
    "* Dal Pozzolo, Andrea Adaptive Machine learning for credit card fraud detection ULB MLG PhD thesis (supervised by G. Bontempi)\n",
    "* Carcillo, Fabrizio; Dal Pozzolo, Andrea; Le Borgne, Yann-Aël; Caelen, Olivier; Mazzer, Yannis; Bontempi, Gianluca. Scarff: a scalable framework for streaming credit card fraud detection with Spark, Information fusion,41, 182-194,2018,Elsevier\n",
    "* Carcillo, Fabrizio; Le Borgne, Yann-Aël; Caelen, Olivier; Bontempi, Gianluca. Streaming active learning strategies for real-life credit card fraud detection: assessment and visualization, International Journal of Data Science and Analytics, 5,4,285-300,2018,Springer International Publishing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
